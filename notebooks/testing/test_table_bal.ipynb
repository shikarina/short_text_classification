{"cells":[{"cell_type":"markdown","source":["# Test results for balanced dataset\n","Test the performance of the obtained trained models on the **balanced dataset**. Create a table with performance scores."],"metadata":{"id":"dZb_p2_JVW-7"}},{"cell_type":"markdown","metadata":{"id":"f0L0IMxiBhlh"},"source":["## Import useful packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MzfNwy0trWGl"},"outputs":[],"source":["# Generic packages\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import copy\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PL4Cu38w4Fr"},"outputs":[],"source":["# Scikit-learn for vectorizers and performance metrics\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.metrics import roc_curve, auc, f1_score, make_scorer, precision_recall_curve, matthews_corrcoef"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJAHaNSwy1EC"},"outputs":[],"source":["# Keras preprocessing\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing import sequence\n","from keras.models import load_model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1648826966926,"user":{"displayName":"Maxime Guirnyk","userId":"12535750245399015042"},"user_tz":-120},"id":"LyHdSClDFrJ9","outputId":"230a4cc0-79d9-4cf1-ffcb-445956329e72"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}],"source":["# NLTK for natural language processing\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIOI76VYgsEg"},"outputs":[],"source":["# Custom helper-functions script (supplied to Colab manually)\n","import utils as uu"]},{"cell_type":"markdown","metadata":{"id":"7E5wAAgKDG4x"},"source":["## Load data and assess performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tljqscAXGAJ1"},"outputs":[],"source":["# Define file names\n","train_set_file = \"train_set_imb_4.csv\"\n","test_set_file  = \"test_set_imb_4.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Actlnf4cnzAU"},"outputs":[],"source":["# Set model-specific load and presentation parameters\n","models = []\n","\n","# CNN model\n","models.append({\n","    \"name\":             \"CNN\",\n","    \"linecolor\":        'red',\n","    \"linestyle\":        '--', \n","    \"marker\":           '.',\n","    \"model_file\":       \"model_cnn_imb_4.h5\",\n","    \"vectorizer\":       \"KERAS\",\n","    \"is_dl_model\":      True,\n","    \"is_lex_model\":     False,\n","    \"max_features\":     100000\n","        })\n","\n","# RF model\n","models.append({\n","    \"name\":             \"RF\",\n","    \"linecolor\":        'orange',\n","    \"linestyle\":        '-', \n","    \"marker\":           'v',\n","    \"model_file\":       \"model_rf_imb_4.pckl\",\n","    \"vectorizer\":       \"COUNT\",\n","    \"is_dl_model\":      False,\n","    \"is_lex_model\":     False,\n","    \"max_features\":     89403\n","        })\n","\n","# LR model\n","models.append({\n","    \"name\":             \"LR\",\n","    \"linecolor\":        'green',\n","    \"linestyle\":        '-', \n","    \"marker\":           '^',\n","    \"model_file\":       \"model_lr_imb_4.pckl\",\n","    \"vectorizer\":       \"TFIDF\",\n","    \"is_dl_model\":      False,\n","    \"is_lex_model\":     False,\n","    \"max_features\":     212435\n","        })\n","\n","# FCNN model\n","models.append({\n","    \"name\":             \"FCNN\",\n","    \"linecolor\":        'deepskyblue',\n","    \"linestyle\":        '--', \n","    \"marker\":           'o',\n","    \"model_file\":       \"model_fcnn_imb_4.h5\",\n","    \"vectorizer\":       \"KERAS\",\n","    \"is_dl_model\":      True,\n","    \"is_lex_model\":     False,\n","    \"max_features\":     100000\n","        })\n","\n","# SVM model\n","models.append({\n","    \"name\":             \"SVM\",\n","    \"linecolor\":        'magenta',\n","    \"linestyle\":        '-', \n","    \"marker\":           '+',\n","    \"model_file\":       \"model_svm_imb_4.pckl\",\n","    \"vectorizer\":       \"TFIDF\",\n","    \"is_dl_model\":      False,\n","    \"is_lex_model\":     False,\n","    \"max_features\":     2710\n","        })\n","\n","# LSTM model\n","models.append({\n","    \"name\":             \"LSTM\",\n","    \"linecolor\":        'purple',\n","    \"linestyle\":        '--',\n","    \"marker\":           'None',\n","    \"model_file\":       \"model_lstm_imb_4.h5\",\n","    \"vectorizer\":       \"KERAS\",\n","    \"is_dl_model\":      True,\n","    \"is_lex_model\":     False,\n","    \"max_features\":     100000\n","        })\n","\n","# NB model\n","models.append({\n","    \"name\":             \"NB\",\n","    \"linecolor\":        'lime',\n","    \"linestyle\":        '-', \n","    \"marker\":           'x',\n","    \"model_file\":       \"model_nb_imb_4.pckl\",\n","    \"vectorizer\":       \"COUNT\",\n","    \"is_dl_model\":      False,\n","    \"is_lex_model\":     False,\n","    \"max_features\":     235808\n","        })\n","\n","# KNN model\n","models.append({\n","    \"name\":             \"KNN\",\n","    \"linecolor\":        'blue',\n","    \"linestyle\":        '-', \n","    \"marker\":           'None',\n","    \"model_file\":       \"model_knn_imb_4.pckl\",\n","    \"vectorizer\":       \"TFIDF\",\n","    \"is_dl_model\":      False,\n","    \"is_lex_model\":     False,\n","    \"max_features\":     100000\n","        })\n","\n","# Lexicon model\n","models.append({\n","    \"name\":             \"Lexicon\",\n","    \"linecolor\":        'black',\n","    \"linestyle\":        '-.', \n","    \"marker\":           'd',\n","    \"model_file\":       \"NA\",\n","    \"vectorizer\":       \"NONE\",\n","    \"is_dl_model\":      False,\n","    \"is_lex_model\":     True,\n","    \"max_features\":     100000\n","        })"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"70a3GbkPGvxh"},"outputs":[],"source":["# Set parameters for tokenization\n","max_words = 5000\n","max_len = 55"]},{"cell_type":"code","source":["# Define a UL lexicon for label \"1\"\n","dict1 = ['climate',\n"," 'climatechange',\n"," 'globalwarming',\n"," 'agw',\n"," 'climaterealists']"],"metadata":{"id":"j83VXV3fbq0i"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35150,"status":"ok","timestamp":1648827002064,"user":{"displayName":"Maxime Guirnyk","userId":"12535750245399015042"},"user_tz":-120},"id":"p0vmnTJXGoka","outputId":"4c7156ef-2fde-4f26-9e20-16ba74c0ea75"},"outputs":[{"output_type":"stream","name":"stdout","text":["model_idx = 0\n","model_idx = 1\n","model_idx = 2\n","model_idx = 3\n","model_idx = 4\n","model_idx = 5\n","model_idx = 6\n","model_idx = 7\n","model_idx = 8\n"]}],"source":["# Compute performance\n","\n","# Load datasets\n","train_set = pd.read_csv(train_set_file)\n","test_set = pd.read_csv(test_set_file)\n","\n","# Preprocess texts\n","train_set['text'] = train_set['text'].apply(str)\n","train_set['text'] = train_set['text'].apply(uu.preprocess_text)\n","test_set['text'] = test_set['text'].apply(str)\n","test_set['text'] = test_set['text'].apply(uu.preprocess_text)\n","\n","# Get features and labels\n","texts_train = copy.deepcopy(train_set['text'])\n","labels_train = copy.deepcopy(train_set['is_about_cc'])\n","texts_test = copy.deepcopy(test_set['text'])\n","labels_test = copy.deepcopy(test_set['is_about_cc'])\n","\n","# Performance dataframe\n","perf = []\n","\n","for model_idx in range(len(models)):\n","\n","  print(\"model_idx = \" + str(model_idx))\n","  \n","  # Load model\n","  if (models[model_idx][\"is_dl_model\"] == True):\n","    model = load_model(models[model_idx][\"model_file\"])\n","  elif (models[model_idx][\"is_lex_model\"] == False):\n","    model = pickle.load(open(models[model_idx][\"model_file\"], 'rb'))\n","\n","  if (models[model_idx][\"vectorizer\"] == \"KERAS\"):\n","    # Tokenize features\n","    tokenizer = Tokenizer(num_words=max_words)\n","    tokenizer.fit_on_texts(texts_train)\n","    sequences_train = tokenizer.texts_to_sequences(texts_train)\n","    features_train = sequence.pad_sequences(sequences_train, maxlen=max_len, padding='post', truncating='post')\n","    sequences_test = tokenizer.texts_to_sequences(texts_test)\n","    features_test = sequence.pad_sequences(sequences_test, maxlen=max_len, padding='post', truncating='post')\n","  elif (models[model_idx][\"vectorizer\"] == \"TFIDF\"):\n","    # Vectorize features\n","    vectorizer = TfidfVectorizer(max_features=models[model_idx][\"max_features\"], lowercase=True, analyzer='word', dtype=np.float32)\n","    vectorizer.fit(texts_train)\n","    features_train = vectorizer.transform(texts_train)\n","    features_test = vectorizer.transform(texts_test)\n","  elif (models[model_idx][\"vectorizer\"] == \"COUNT\"):\n","    vectorizer = CountVectorizer()\n","    vectorizer.fit(texts_train)\n","    features_train = vectorizer.transform(texts_train)\n","    features_test = vectorizer.transform(texts_test)\n","    \n","  # Compute performance metrics\n","\n","  # Predicted labels\n","  if (models[model_idx][\"is_lex_model\"] == True):\n","    pred_labels = [1 if any(word in text.split() for word in dict1) else 0 for text in texts_test]\n","  else:\n","    pred_labels = (model.predict(features_test) > 0.5).astype(int)\n","\n","  # Accuracy, precision, recall and F1 score\n","  acc, prec, rec, f1 = uu.compute_perf_metrics(labels_test, pred_labels)\n","\n","  # Prediction scores\n","  if (models[model_idx][\"name\"] == \"LR\") or (models[model_idx][\"name\"] == \"SVM\"):\n","    pred_scores = model.decision_function(features_test)\n","  elif (models[model_idx][\"name\"] == \"RF\") or (models[model_idx][\"name\"] == \"NB\") or (models[model_idx][\"name\"] == \"KNN\"):\n","    pred_scores = model.predict_proba(features_test)[:, 1]\n","  elif (models[model_idx][\"name\"] == \"Lexicon\"):\n","    pred_scores = [uu.occurrence_counter(text.split(), dict1) for text in texts_test]\n","  elif (models[model_idx][\"name\"] == \"CNN\") or (models[model_idx][\"name\"] == \"FCNN\") or (models[model_idx][\"name\"] == \"LSTM\"):\n","    pred_scores = model.predict(features_test).ravel()\n","\n","  # Area under ROC curve\n","  fpr, tpr = uu.compute_roc(labels_test, pred_scores)\n","  roc_auc = auc(fpr, tpr)\n","\n","  # Area uner PR curve\n","  precs, recs = uu.compute_pr(labels_test, pred_scores)\n","  pr_auc = auc(recs, precs)\n","\n","  # Matthews correlation coeficient\n","  mcc = matthews_corrcoef(labels_test, pred_labels)\n","\n","  # Gather all metrics\n","  perf.append([models[model_idx][\"name\"], acc, prec, rec, f1, roc_auc, pr_auc, mcc])\n","\n","# Combine into a dataframe\n","df_perf = pd.DataFrame(perf, columns=['Method', 'Accuracy', 'Precision', 'Recall', 'F1 score', 'AUC ROC', 'AUC PR', 'MCC'])"]},{"cell_type":"code","source":["# Performance comparison\n","df_perf"],"metadata":{"id":"1wOmZCNprOs4","colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"status":"ok","timestamp":1648827002065,"user_tz":-120,"elapsed":23,"user":{"displayName":"Maxime Guirnyk","userId":"12535750245399015042"}},"outputId":"e4dcb000-ef3a-4763-9664-c79bcc47c83f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Method  Accuracy  Precision    Recall  F1 score   AUC ROC    AUC PR  \\\n","0      CNN  0.970551   0.977128  0.963659  0.970347  0.990883  0.992459   \n","1       RF  0.970551   0.992136  0.948622  0.969891  0.990770  0.993153   \n","2       LR  0.969298   0.980745  0.957393  0.968928  0.990146  0.992391   \n","3     FCNN  0.968045   0.977011  0.958647  0.967742  0.989988  0.991918   \n","4      SVM  0.968045   0.979461  0.956140  0.967660  0.988149  0.991014   \n","5     LSTM  0.961153   0.956576  0.966165  0.961347  0.986301  0.987585   \n","6       NB  0.960526   0.955390  0.966165  0.960748  0.989931  0.992488   \n","7      KNN  0.895363   0.846323  0.966165  0.902282  0.972934  0.974146   \n","8  Lexicon  0.875313   0.995041  0.754386  0.858161  0.875384  0.936210   \n","\n","        MCC  \n","0  0.941192  \n","1  0.942009  \n","2  0.938863  \n","3  0.936256  \n","4  0.936356  \n","5  0.922352  \n","6  0.921111  \n","7  0.798776  \n","8  0.773593  "],"text/html":["\n","  <div id=\"df-dc02008a-25c5-4e65-a342-4a81ef29dd09\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Method</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 score</th>\n","      <th>AUC ROC</th>\n","      <th>AUC PR</th>\n","      <th>MCC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CNN</td>\n","      <td>0.970551</td>\n","      <td>0.977128</td>\n","      <td>0.963659</td>\n","      <td>0.970347</td>\n","      <td>0.990883</td>\n","      <td>0.992459</td>\n","      <td>0.941192</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>RF</td>\n","      <td>0.970551</td>\n","      <td>0.992136</td>\n","      <td>0.948622</td>\n","      <td>0.969891</td>\n","      <td>0.990770</td>\n","      <td>0.993153</td>\n","      <td>0.942009</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LR</td>\n","      <td>0.969298</td>\n","      <td>0.980745</td>\n","      <td>0.957393</td>\n","      <td>0.968928</td>\n","      <td>0.990146</td>\n","      <td>0.992391</td>\n","      <td>0.938863</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>FCNN</td>\n","      <td>0.968045</td>\n","      <td>0.977011</td>\n","      <td>0.958647</td>\n","      <td>0.967742</td>\n","      <td>0.989988</td>\n","      <td>0.991918</td>\n","      <td>0.936256</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>SVM</td>\n","      <td>0.968045</td>\n","      <td>0.979461</td>\n","      <td>0.956140</td>\n","      <td>0.967660</td>\n","      <td>0.988149</td>\n","      <td>0.991014</td>\n","      <td>0.936356</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LSTM</td>\n","      <td>0.961153</td>\n","      <td>0.956576</td>\n","      <td>0.966165</td>\n","      <td>0.961347</td>\n","      <td>0.986301</td>\n","      <td>0.987585</td>\n","      <td>0.922352</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NB</td>\n","      <td>0.960526</td>\n","      <td>0.955390</td>\n","      <td>0.966165</td>\n","      <td>0.960748</td>\n","      <td>0.989931</td>\n","      <td>0.992488</td>\n","      <td>0.921111</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>KNN</td>\n","      <td>0.895363</td>\n","      <td>0.846323</td>\n","      <td>0.966165</td>\n","      <td>0.902282</td>\n","      <td>0.972934</td>\n","      <td>0.974146</td>\n","      <td>0.798776</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Lexicon</td>\n","      <td>0.875313</td>\n","      <td>0.995041</td>\n","      <td>0.754386</td>\n","      <td>0.858161</td>\n","      <td>0.875384</td>\n","      <td>0.936210</td>\n","      <td>0.773593</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc02008a-25c5-4e65-a342-4a81ef29dd09')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dc02008a-25c5-4e65-a342-4a81ef29dd09 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dc02008a-25c5-4e65-a342-4a81ef29dd09');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# Save into a file\n","df_perf.to_csv(\"tab_bal_metrics.csv\", index=False)"],"metadata":{"id":"fsqOlM2IyuXI"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyOB5jH2JzBq9MckFZ2WCWmH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}