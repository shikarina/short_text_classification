{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"tune_rf_imb.ipynb","provenance":[{"file_id":"1snwNGx2iqZecebnIHRte9w5OZI-wiDIc","timestamp":1645380111180}],"collapsed_sections":[],"authorship_tag":"ABX9TyO335xZi4A8toRJNDbDMZDK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tuning the RF classifier\n","\n","Hyperparameter sweep for the **random forest classifier** for producing results with various **degrees of dataset imbalance**. Optimize the hyperparameters for the worst-case imbalance configuration. Optimization conducted by means of the tree-structured Parzen estimator."],"metadata":{"id":"-U4l8xD0VWYi"}},{"cell_type":"markdown","source":["## Import useful packages"],"metadata":{"id":"no4vU4t789kD"}},{"cell_type":"code","metadata":{"id":"MzfNwy0trWGl"},"source":["# Generic packages\n","import numpy as np\n","import pandas as pd\n","import copy\n","import sys"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1pyiZVdwd2A"},"source":["# Sci-kit learn for machine learning tasks\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import class_weight\n","from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score, make_scorer\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qUY1ROwvlJ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645655787672,"user_tz":-60,"elapsed":1098,"user":{"displayName":"Maxime Guirnyk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gguy3irsE8K--Flon8AVFeNltIBnbtO2b51t-pMSw=s64","userId":"12535750245399015042"}},"outputId":"434d4804-effa-4091-eab0-df66df97e349"},"source":["# NLTK for natural language processing\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}]},{"cell_type":"code","source":["# HyperOptfor Bayesian optimization\n","from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n","from hyperopt.pyll import scope"],"metadata":{"id":"C_SVjd0B-k-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Custom helper-functions script (supplied to Colab manually)\n","import utils as uu"],"metadata":{"id":"gR2Ux2hd9Qv8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load and process data"],"metadata":{"id":"yfbPppEy9tRr"}},{"cell_type":"code","metadata":{"id":"H8XFPdmEse2Z"},"source":["# Load training set\n","train_set_file  = \"train_set_imb_0.csv\"\n","train_set = pd.read_csv(train_set_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wKohdm1up6L"},"source":["# Preprocess texts\n","train_set['text'] = train_set['text'].apply(str)\n","train_set['text'] = train_set['text'].apply(uu.preprocess_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"juN74NFUxQpG"},"source":["# Decouple texts and labels (deep copy to not modfy the original datasets accidentally)\n","texts_train = copy.deepcopy(train_set['text'])\n","labels_train = copy.deepcopy(train_set['is_about_cc'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define hyperparameter search space and objective function"],"metadata":{"id":"fLoAkXZI-alg"}},{"cell_type":"code","source":["# Define the search space for hyperparameterss\n","hyperparam_space = {'max_features': scope.int(hp.qloguniform('max_features', np.log(5e3), np.log(5e5), q=1)),\n","                    'max_depth': scope.int(hp.quniform('max_depth', 5, 25, q=1)),\n","                    'n_estimators': scope.int(hp.qloguniform('n_estimators', np.log(1e1), np.log(1e3), q=1)),\n","                    'vectorizer': hp.choice('vectorizer', ['tfidf', 'count']),\n","                    }"],"metadata":{"id":"IJbmqqb6mIog"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the objective function for optimization\n","def objective(params):   \n","    print ('Params testing: ', params)\n","\n","    # Split dataset into training validation sets\n","    inp_train, inp_valid, lbl_train, lbl_valid = train_test_split(texts_train, labels_train, \n","                                                                  test_size=0.15, \n","                                                                  random_state=12345, \n","                                                                  stratify=labels_train)\n","    \n","    # Compute class weights for compensation the imbalance in classes\n","    class_weights = class_weight.compute_class_weight(class_weight = \"balanced\", classes = np.unique(lbl_train), y = lbl_train)\n","    class_weights = dict(zip(np.unique(lbl_train), class_weights))\n","\n","    # Set vectorizer\n","    if params['vectorizer']=='tfidf':\n","        vectorizer = TfidfVectorizer(max_features=params['max_features'], lowercase=True, analyzer='word', dtype=np.float32)\n","    elif params['vectorizer']=='count':\n","        vectorizer = CountVectorizer()\n","    else:\n","        sys.exit(\"Unsupported vectorizer!\")\n","\n","    # Fit vectorizer\n","    vectorizer.fit(inp_train)\n","    features_train = vectorizer.transform(inp_train)\n","    features_valid = vectorizer.transform(inp_valid)\n","\n","    # Define the model\n","    model = RandomForestClassifier(max_depth=params['max_depth'], n_estimators=params['n_estimators'], class_weight=class_weights)\n","    \n","    # Fit the model\n","    model.fit(features_train, lbl_train)\n","\n","    # Compute performance of the trial\n","    pred_scores = (model.predict(features_valid) > 0.5).astype(\"int32\")\n","    f1 = f1_score(lbl_valid, pred_scores)\n","    print('DONE!      F1 = ' + str(f1))\n","    sys.stdout.flush() \n","    return {'loss': -f1, 'status': STATUS_OK}\n"],"metadata":{"id":"g-X_tx3wmZWk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run Bayesian optimization with Tree Parzen Estimator"],"metadata":{"id":"mQLFRd8rBoLs"}},{"cell_type":"code","source":["trials = Trials()\n","best = fmin(objective, hyperparam_space, algo=tpe.suggest, max_evals=1e3, trials=trials)\n","print('Best hyperparams: ', best)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"Wq0FnXvhmL7C","executionInfo":{"status":"error","timestamp":1647595356127,"user_tz":-60,"elapsed":330,"user":{"displayName":"Maxime Guirnyk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gguy3irsE8K--Flon8AVFeNltIBnbtO2b51t-pMSw=s64","userId":"12535750245399015042"}},"outputId":"82d0b6f4-5e12-4755-c354-0785f8343b5e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-73fd985e0b88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparam_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best hyperparams: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Trials' is not defined"]}]}]}